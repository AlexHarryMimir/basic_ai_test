<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Network Toy</title>
</head>
<style>
    .configuration_menu {
        width: max-content;
        border: solid 1px black;
        display: flex;
        padding: 10px;
    }

    .controls {
        display: flex;
    }

    .set_functions {
        display: flex;
        flex-direction: column;
    }

    .neural_network {
        display: flex;
        flex-direction: row;
        min-width: 420px;
        min-height: 420px;
        overflow: scroll;
        border: solid 1px black;
    }

    .info_box {
        width: 200px;
        height: 200px;
        border: solid 1px black;
        border-radius: 20px;
        font-size: 8pt;
        overflow-y: scroll;
        padding: 5px;
        background-color: lightgrey;
        z-index: 1;
        position: absolute;
        display: none;
    }

    .feature_layer {
        display: flex;
        flex-direction: column;
        justify-content: space-around;
        height: fill;
    }

    .hidden_layers {
        display: flex;
    }

    .hidden_layer {
        display: flex;
        flex-direction: column;
        justify-content: space-around;

    }

    .output_layer {
        display: flex;
        flex-direction: column;
        justify-content: space-around;

    }

    .neuron {
        border-top: 1px solid black;
        border-bottom: 1px solid black;
        display: flex;
        justify-content: space-between;
        flex-grow: 1;
        margin-top: auto;
        margin-bottom: auto;
    }

    .feature_input {
        background-color: lightcyan;
        border: solid 1px black;

        border-radius: 10px;
    }

    .output_neuron {
        border-top: 1px solid black;
        border-bottom: 1px solid black;
        display: flex;
        justify-content: space-between;
        flex-grow: 1;
        margin-top: auto;
        margin-bottom: auto;
    }

    .weights_text {
        display: flex;
        flex-direction: column;
        justify-content: space-around;
    }

    .activation_text {
        margin-top: auto;
        margin-bottom: auto;
        display: flex;
        flex-direction: column;
        text-align: center;
        justify-content: space-around;
        height: 80px;
        width: 80px;
        border: 1px black solid;
        border-radius: 50%;
    }

    .error_text {
        color: red;
    }

    .bias_text {
        display: flex;
        flex-direction: column;
        justify-content: space-around;
    }
</style>

<body>
    <div class="configuration_menu" id="configuration_menu">
        <div>
            <div>Number of features</div>
            <div id="num_feature_text"></div>
            <input type="range" min="1" max="4" id="feature_slider">
            <div>Number of Hidden Layers</div>
            <div id="num_hidden_layers_text"></div>
            <input type="range" min="1" max="8" id="hidden_layers_slider">
            <div>Size of Hidden Layers</div>
            <div id="len_hidden_layers_text"></div>
            <input type="range" min="1" max="16" id="len_hidden_layers_slider">
            <div>Number of Output Neurons</div>
            <div id="num_output_neuron_text"></div>
            <input type="range" min="1" max="4" id="num_output_neuron_slider">
            <!--color choices for the neron types-->
            <div>Learning Rate</div>
            <div id="lr_text"></div>
            <input type="range" min="1" max="1000" id="lr">
            <div>Mini Batch Size</div>
            <div id="training_set_size_text"></div>
            <input type="range" min="1" max="500" id="training_set_size">
            <div>Number of Epochs</div>
            <div id="num_epochs_text"></div>
            <input type="range" min="1" max="50" id="num_epochs">
            <div>Batch Training</div>
            <input type="checkbox" checked id="en_batch_training">
            <div>Activation Function</div>
            <div style="display: flex;">
                <div>
                    <div>ReLU</div>
                    <input type="checkbox" class="activation_function_options" id="ReLU">
                </div>
                <div style="width:10px"></div>
                <div>
                    <div>Leaky ReLU</div>
                    <input type="checkbox" class="activation_function_options" id="Leaky ReLU">
                </div>
                <div style="width:10px"></div>
                <div>
                    <div>GELU</div>
                    <input type="checkbox" class="activation_function_options" id="GELU">
                </div>
                <div style="width:10px"></div>
                <div>
                    <div>Sigmoid</div>
                    <input type="checkbox" class="activation_function_options" id="Sigmoid">
                </div>
            </div>
        </div>
        <div>
            <button onclick="display_info()">i</button>
            <div id="functions_info" class="info_box">Define the behavior of the output neurons by writing a simple
                function in these boxes. To denote a neuron as an imput to a function use {#}. <br>Example:<br>{0}*{1}
                would set the associated output Neuron to be trained to produce the prodcut of the first and second
                feature</div>

            <div class="set_functions" id="output_functions">
            </div>
        </div>
        <div><canvas id="accuracy_graph" width="600" height="450" style="border: 1px solid black"></canvas>
            <div style="width: 100%; text-align: center;">Error to Training Epochs</div>
        </div>


    </div>
    <div class="controls">
        <button type="button" id="generate_network">Generate Network</button>
        <button type="button" id="Train_network" onclick="train_network()">Train Network</button>
        <button type="button" id="run_example" onclick="compute_results()">Compute
            Result</button><!--todo allow user to input values-->
        <button type="button" id="randomize_data"
            onclick="randomize_values()">Randomize</button><!--todo allow user to input values-->
    </div>
    <div class="neural_network" id="neural_network">


    </div>
    </div>

</body>
<script>

    class input {
        constructor(activation_text) {
            this.activation = 0.0;
            this.activation_text = activation_text;
        }
        update_text() {
            this.activation_text.value = String(this.activation);
        }
    }

    class neuron {
        constructor(weight_texts, activation_text, bias_text, error_text) {
            this.weights = new Array(weight_texts.length).fill(0);
            this.weight_texts = weight_texts;
            this.activation = 0.0;
            this.activation_text = activation_text;
            this.bias = 0.0;
            this.bias_text = bias_text;
            this.error = 0.0;
            this.error_text = error_text;
            this.batch_weight_error = new Array(weight_texts.length);
            this.batch_bias_error = 0.0;
        }
        calculate_activation() {
            this.activation = 1.0;
        }
        update_text() {
            for (let i = 0; i < this.weights.length; i++) {
                this.weight_texts[i].innerHTML = String(Math.round(this.weights[i] * 1000) / 1000);
            }
            this.bias_text.innerHTML = String(Math.round(this.bias * 1000) / 1000);
            this.activation_text.innerHTML = String(Math.round(this.activation * 1000) / 1000);
            this.error_text.innerHTML = String(Math.round(this.error * 1000) / 1000)
        }
    }
    
    //activation function enumeration
    const ReLU = 0;
    const LeakyReLU = 1;
    const GELU = 2;
    const Sigmoid = 3;
    class activation_function_t {
        constructor(activation_function_i){
            this.type = activation_function_i
        }
        activation(n){
            switch (this.type){
                case ReLU:
                    n.activation += n.bias;
                    if (n.activation <= 0){
                        return 0;
                    }
                    return n.activation;
                case LeakyReLU:
                    n.activation += n.bias;
                    if (n.activation <= 0){
                        return n.activation * .01;
                    }
                    return n.activation;
                case GELU:
                    n.activation += n.bias;
                    let a = Math.sqrt(2 / Math.PI);
                    let b = 0.044715 * Math.pow(n.activation, 3);
                    return 0.5 * n.activation * (1 + Math.tanh(a * (n.activation + b)));
                case Sigmoid:
                    n.activation += n.bias;
                    return 1 / (1 + Math.exp(-n.activation));
                default:
                    return 0;
            }
        }
        derivative_wrt_w(n){
            switch (this.type){
                case ReLU:
                    if (n.activation <= 0){
                        return 0.0;
                    }
                    return 1.0;
                case LeakyReLU:
                    if (n.activation <= 0){
                        return 0.01;
                    }
                    return 1.0;
                case GELU:
                    const sqrt2OverPi = Math.sqrt(2 / Math.PI);
                    const a = 0.044715;
                    const tanhTerm = Math.tanh(sqrt2OverPi * (n.activation + a * Math.pow(n.activation, 3)));
                    const sechTerm = Math.pow(1/Math.cosh(sqrt2OverPi * (n.activation + a * Math.pow(n.activation, 3))), 2);
                    return (0.5 * (1 + tanhTerm) + 0.5 * n.activation * sechTerm * sqrt2OverPi * (1 + 3 * a * Math.pow(n.activation, 2)));
                case Sigmoid:
                    let sig = 1 / (1 + Math.exp(-n.activation));
                    return sig * (1 - sig);
                default:
                    return 0;
            }
        }
        derivative_wrt_b(n){
            switch (this.type){
                case ReLU:
                    return 1.0;
                case LeakyReLU:
                    return 1.0;
                case GELU:
                    return 1.0;
                case Sigmoid:
                    return 1.0;
                default:
                    return 0;
            }
        }

    }
    //global variables
    var activation_function = new activation_function_t(ReLU); //todo set init on load
    //network sizes
    var nFeatures;
    var nHiddenLayers;
    var nSizeHiddenLayers;
    var nOutputNerons;
    var setupNOutputNeurons;
    //network objects
    var features; //array of input class
    var hidden; //2d array of neurons
    var outputs; //array of neurons
    //network behavior elements
    var functions; //todo don't force regeneration of network to update functions //update when run
    var lr; //learning rate
    var batch_size;
    var num_epochs;

    var error_graph = document.getElementById("accuracy_graph");
    var error_graph_context = error_graph.getContext("2d");

    var accuracy_record = [];
    
    //slider event handling:
    {
        //feature slider:
        document.getElementById("feature_slider").oninput = function () {
            document.getElementById("num_feature_text").innerHTML = this.value;
        }
        document.getElementById("hidden_layers_slider").oninput = function () {
            document.getElementById("num_hidden_layers_text").innerHTML = this.value;
        }
        document.getElementById("len_hidden_layers_slider").oninput = function () {
            document.getElementById("len_hidden_layers_text").innerHTML = this.value;
        }
        document.getElementById("lr").oninput = function () {
            document.getElementById("lr_text").innerHTML = String(this.value / 1000);
            lr = (this.value) / 1000;
        }
        document.getElementById("num_output_neuron_slider").oninput = function () {
            document.getElementById("num_output_neuron_text").innerHTML = this.value;
            setupNOutputNeurons = this.value;
            let output_functions_str = "";
            for (let i = 0; i < this.value; i++) {
                output_functions_str += "<input class=\"textbox\" type=\"text\" id=\"textbox" + i + "\">\n"
            }
            document.getElementById("output_functions").innerHTML = output_functions_str;
        }
        document.getElementById("training_set_size").oninput = function () {
            document.getElementById("training_set_size_text").innerHTML = this.value;
            batch_size = this.value
        }
        document.getElementById("num_epochs").oninput = function () {
            document.getElementById("num_epochs_text").innerHTML = this.value;
            num_epochs = this.value;
        }
    }
    {
        Array.prototype.forEach.call(document.getElementsByClassName("activation_function_options"), function(e) {
            e.onchange = function() {
                let tid = this.id;
                Array.prototype.forEach.call(document.getElementsByClassName("activation_function_options"), function(element){
                    if (tid != element.id){
                        element.checked = false;
                    }
                })
                switch (tid){
                    case "ReLU":
                        activation_function.type = ReLU;
                        break;
                    case "Leaky ReLU":
                        activation_function.type = LeakyReLU;
                        break;
                    case "GELU":
                        activation_function.type = GELU;
                        break;
                    case "Sigmoid":
                        activation_function.type = Sigmoid;
                        break;
                }
            }
        })
    }
    window.onload = function () {
        //onload capture the state of the sliders
        document.getElementById("num_feature_text").innerHTML = document.getElementById("feature_slider").value;
        document.getElementById("num_hidden_layers_text").innerHTML = document.getElementById("hidden_layers_slider").value;
        document.getElementById("len_hidden_layers_text").innerHTML = document.getElementById("len_hidden_layers_slider").value;
        batch_size = document.getElementById("training_set_size").value;
        document.getElementById("training_set_size_text").innerHTML = batch_size;
        lr = document.getElementById("lr").value / 1000;
        document.getElementById("lr_text").innerHTML = String(lr);
        num_epochs = document.getElementById("num_epochs").value;
        document.getElementById("num_epochs_text").innerHTML = String(num_epochs);
        setupNOutputNeurons = document.getElementById("num_output_neuron_slider").value;
        document.getElementById("num_output_neuron_text").innerHTML = String(setupNOutputNeurons);
        let output_functions_str = "";
        for (let i = 0; i < setupNOutputNeurons; i++) {
            output_functions_str += "<input class=\"textbox\" type=\"text\" id=\"textbox" + i + "\">\n"
        }
        document.getElementById("output_functions").innerHTML = output_functions_str;
        let temp_e;
        Array.prototype.forEach.call(document.getElementsByClassName("activation_function_options"), function(element){
            if (element.checked){
                switch (element.id){
                    case "ReLU":
                        activation_function.type = ReLU;
                        break;
                    case "Leaky ReLU":
                        activation_function.type = LeakyReLU;
                        break;
                    case "GELU":
                        activation_function.type = GELU;
                        break;
                    case "Sigmoid":
                        activation_function.type = Sigmoid;
                        break;
                }
                temp_e = element;
                element.checked = false;
            }
        });
        temp_e.checked = true;//check the only enabled function

        
    };

    function display_info() {
        let i_box = document.getElementById("functions_info");
        if (i_box.style.display == "none") {
            i_box.style.display = "block";
        } else {
            i_box.style.display = "none";
        }
    }


    document.getElementById("generate_network").addEventListener("click", function (e) {
        //update globals of network status
        nFeatures = Number(document.getElementById("feature_slider").value);
        nHiddenLayers = Number(document.getElementById("hidden_layers_slider").value);
        nSizeHiddenLayers = Number(document.getElementById("len_hidden_layers_slider").value);
        nOutputNerons = Number(setupNOutputNeurons);

        //create HTML for network display
        var nn = "<div class=\"feature_layer\" id=\"feature_layer\">";
        for (let i = 0; i < nFeatures; i++) {
            nn += "<div id=\"f" + i + "\">";
            nn += "<div class=\"feature_neuron\"><div class=\"activation_text\" style=\"background-color: aqua;\"><input class=\"feature_input\" type=\"text\"></div></div>"
            nn += "</div>";
        }
        nn += "</div>";

        let canvas_height;
        //todo choose a better way to pick canvas height
        //todo label the columns as wights, biases, activations and features
        if (nSizeHiddenLayers > nFeatures) {
            canvas_height = nSizeHiddenLayers * 100;
        } else {
            canvas_height = nFeatures * 100;
        }
        nn += "<canvas id=\"feature_canvas\" width=\"100\" height=\"" + canvas_height + "\">"
        nn += "</canvas>"

        nn += "<div class=\"hidden_layers\" id=\"hidden_layers\">";
        for (let i = 0; i < nHiddenLayers; i++) {
            nn += "<div class=\"hidden_layer\" id=\"hidden_layer" + i + "\">";
            for (let j = 0; j < nSizeHiddenLayers; j++) {
                nn += "<div class=\"neuron\" id=\"h" + i + "n" + j + "\"><div class=\"weights_text\">";
                if (i == 0) {
                    for (let k = 0; k < nFeatures; k++) {
                        nn += "<div class=\"individual_weight\">0.0</div>";
                    }
                } else {
                    for (let k = 0; k < nSizeHiddenLayers; k++) {
                        nn += "<div class=\"individual_weight\">0.0</div>";
                    }
                }
                nn += "</div><div class=\"activation_text\" style=\"background-color: lightblue;\">0.0</div><div class=\"bias_text\">0.0</div><div class=\"error_text\">0.0</div></div>";
            }
            nn += "</div>";
            if (i < nHiddenLayers - 1) {
                nn += "<canvas width=\"100\" class=\"hidden_layer_net\" height=\"" + canvas_height + "\">"
                nn += "</canvas>"
            }
        }
        nn += "</div>";

        nn += "<canvas id=\"output_canvas\" width=\"100\" height=\"" + (canvas_height) + "\">"
        nn += "</canvas>"

        nn += "<div class=\"output_layer\" id=\"output_layer\">";
        for (let i = 0; i < nOutputNerons; i++) {
            nn += "<div id=\"o" + i + "\"><div class=\"output_neuron\"><div class=\"weights_text\">";
            for (let k = 0; k < nSizeHiddenLayers; k++) {
                nn += "<div class=\"individual_weight\">0.0</div>";
            }
            nn += "</div><div class=\"activation_text\" style=\"background-color: darkred; color: wheat;\">0.0</div><div class=\"bias_text\">0.0</div><div class=\"error_text\">0.0</div></div></div>";
        }
        nn += "</div>";
        //push update
        document.getElementById("neural_network").innerHTML = nn;

        //setup network datastructures
        let fn = document.getElementsByClassName("feature_neuron");
        features = []
        Array.prototype.forEach.call(fn, function (element) {
            features.push(
                new input(
                    element.children[0].children[0]
                )
            );
        })
        let hl = document.getElementsByClassName("hidden_layer");
        hidden = []
        Array.prototype.forEach.call(hl, function (element) {
            let current_hln = [];
            Array.prototype.forEach.call(element.children, function (e) {
                current_hln.push(new neuron(
                    e.children[0].children,
                    e.children[1],
                    e.children[2],
                    e.children[3]
                ))
            })
            hidden.push(current_hln);
        })

        let on = document.getElementsByClassName("output_neuron");
        outputs = []
        Array.prototype.forEach.call(on, function (element) {
            outputs.push(
                new neuron(
                    element.children[0].children,
                    element.children[1],
                    element.children[2],
                    element.children[3]
                )
            );
        })

        //draw lines to canvases
        let feature_canvas = document.getElementById("feature_canvas").getContext("2d");
        let feature_spacing = (canvas_height / nFeatures);
        let feature_offset = (feature_spacing) / 2;
        let hidden_spacing = (canvas_height / nSizeHiddenLayers);
        let hidden_offset = hidden_spacing / 2;
        for (let i = 0; i < nFeatures; i++) {
            for (let j = 0; j < nSizeHiddenLayers; j++) {
                feature_canvas.moveTo(0, (i * feature_spacing) + feature_offset);
                feature_canvas.lineTo(100, (j * hidden_spacing) + hidden_offset);
            }
        }
        feature_canvas.stroke();

        Array.prototype.forEach.call(document.getElementsByClassName("hidden_layer_net"), function (element) {
            var current_layer_net = element.getContext("2d");
            for (let i = 0; i < nSizeHiddenLayers; i++) {
                for (let j = 0; j < nSizeHiddenLayers; j++) {
                    current_layer_net.moveTo(0, (i * hidden_spacing) + hidden_offset);
                    current_layer_net.lineTo(100, (j * hidden_spacing) + hidden_offset);
                }
            }
            current_layer_net.stroke();
        });

        var output_canvas = document.getElementById("output_canvas").getContext("2d");
        let output_spacing = (canvas_height / nOutputNerons);
        let output_offset = output_spacing / 2;
        for (let i = 0; i < nSizeHiddenLayers; i++) {
            for (let j = 0; j < nOutputNerons; j++) {
                output_canvas.moveTo(0, (i * hidden_spacing) + hidden_offset);
                output_canvas.lineTo(100, (j * output_spacing) + output_offset);
            }
        }
        output_canvas.stroke();
    });

    function update_text() {
        features.forEach(function (element) {
            element.update_text();
        })
        hidden.forEach(function (element) {
            element.forEach(function (e) {
                e.update_text();
            })
        })
        outputs.forEach(function (element) {
            element.update_text();
        })
        let delta_x = error_graph.width / (accuracy_record.length-1);
        let delta_y = error_graph.height / (Math.sqrt(Math.max(...accuracy_record)));
        error_graph_context.clearRect(0, 0, error_graph.width, error_graph.height);
        error_graph_context.beginPath();
        error_graph_context.moveTo(0, error_graph.height - delta_y * Math.sqrt(accuracy_record[0]));
        for (let i = 1; i < accuracy_record.length; i++) {
            error_graph_context.lineTo(i * delta_x, error_graph.height - (delta_y * Math.sqrt(accuracy_record[i])));
        }
        error_graph_context.stroke();

    }

    function train_network() {
        //capture current functions to train to
        functions = [];
        Array.prototype.forEach.call(document.getElementsByClassName("textbox"), function (element) {
            functions.push(element.value);
        })
        //each iteration of an epock pushes a batch worth of update(s)
        for (let epoch = 0; epoch < num_epochs; epoch++) {
            //each epock is a point of accuracy on the graph
            var epoch_accuracy = 0.0;
            if (document.getElementById("en_batch_training").checked) { //if batched then an update is only pushed once per batch, if not batched, each iteration is a new update
                //setup averaging of errors
                for (let i = 0; i < hidden.length; i++) {
                    for (let j = 0; j < hidden[i].length; j++) {
                        for (let k = 0; k < hidden[i][j].batch_weight_error.length; k++) {
                            hidden[i][j].batch_weight_error[k] = 0.0;
                        }
                        hidden[i][j].batch_bias_error = 0.0;
                    }
                }
                for (let i = 0; i < outputs.length; i++) {
                    for (let k = 0; k < outputs[i].batch_weight_error.length; k++) {
                        outputs[i].batch_weight_error[k] = 0.0;
                    }
                    outputs[i].batch_bias_error = 0.0;
                }
                //calculate the summ of errors for each iteration in the batch
                for (let batch = 0; batch < batch_size; batch++) {
                    //initilize input values and forward propogate the computation of the network (ie inference)
                    Array.prototype.forEach.call(features, function (element) {
                        element.activation = Math.random();
                    })
                    inference();
                    //add error to sum of the batch error
                    for (let i = 0; i < hidden.length; i++) {
                        for (let j = 0; j < hidden[i].length; j++) {
                            if (i == 0) {
                                for (let k = 0; k < hidden[i][j].weights.length; k++) {
                                    hidden[i][j].batch_weight_error[k] += (hidden[i][j].error) * features[k].activation * Math.abs(hidden[i][j].weights[k]) * activation_function.derivative_wrt_w(hidden[i][j]);
                                }
                            } else {
                                for (let k = 0; k < hidden[i][j].weights.length; k++) {
                                    hidden[i][j].batch_weight_error[k] += (hidden[i][j].error) * hidden[i - 1][j].activation * Math.abs(hidden[i][j].weights[k]) * activation_function.derivative_wrt_w(hidden[i][j]);
                                }
                            }
                            hidden[i][j].batch_bias_error += hidden[i][j].error * activation_function.derivative_wrt_b(hidden[i][j]);
                        }
                    }
                    //in adition to accululating error calculate the network accuracy in MSE of the training case
                    let current_epoch = 0.0;
                    for (let i = 0; i < outputs.length; i++) {
                        for (let k = 0; k < outputs[i].weights.length; k++) {
                            outputs[i].batch_weight_error[k] += (outputs[i].error) * (hidden[hidden.length - 1][k].activation) * Math.abs(outputs[i].weights[k]) * activation_function.derivative_wrt_w(outputs[i]);
                        }
                        outputs[i].batch_bias_error += outputs[i].error * activation_function.derivative_wrt_b(outputs[i]);
                        current_epoch += outputs[i].error ** 2;
                    }
                    epoch_accuracy += (current_epoch / outputs.length) ** 2;
                }
                //store MSE of the batch 
                accuracy_record.push(epoch_accuracy / batch_size);

                //push update of the batch error
                adjust_network_values(true);
            } else {
                //adjust each weight on each iteration (no batching)
                for (let batch = 0; batch < batch_size; batch++) {
                    //randomize inputs and forward propogate them (ie inference)
                    Array.prototype.forEach.call(features, function (element) {
                        element.activation = Math.random();
                    })
                    inference();
                    //collect accuracy data as MSE for case in epoch
                    let current_epoch = 0.0
                    for (let i = 0; i < outputs.length; i++) {
                        current_epoch += outputs[i].error ** 2;
                    }
                    epoch_accuracy += (current_epoch / outputs.length) ** 2;
                    //adjust values on each iteration
                    adjust_network_values(false);
                }

                //push update to network for the iteration
                accuracy_record.push(epoch_accuracy / batch_size);
            }
        }
        inference();
        update_text();
    }

    //inference a single example given by the user
    function compute_results() {
        //if the functions are updated before computing a result the error will be different
        functions = [];
        Array.prototype.forEach.call(document.getElementsByClassName("textbox"), function (element) {
            functions.push(element.value);
        })
        //capture current value of inputs as set by user
        Array.prototype.forEach.call(features, function (element) {
            element.activation = Number(element.activation_text.value);
        })
        inference();
        update_text();
    }

    //randomize between 1 and -1
    function randomize() {
        return Math.random() - Math.round(Math.random());
    }
    //randomize the entire network initial values
    function randomize_values() {
        //Randomize between 0 and 1 for features
        Array.prototype.forEach.call(features, function (element) {
            element.activation = Math.random();
        })
        Array.prototype.forEach.call(hidden, function (element) {
            Array.prototype.forEach.call(element, function (e) {
                for (let i = 0; i < e.weights.length; i++) {
                    e.weights[i] = randomize();
                }
                e.bias = randomize();
            })
        })
        Array.prototype.forEach.call(outputs, function (element) {
            for (let i = 0; i < element.weights.length; i++) {
                element.weights[i] = randomize();
            }
            element.bias = randomize();
        })

        //capture functions before measuring network accuracy
        functions = [];
        Array.prototype.forEach.call(document.getElementsByClassName("textbox"), function (element) {
            functions.push(element.value);
        })
        //get an initial network accuracy estimate
        let current_epoch = 0.0;
        for (let i = 0; i < batch_size; i++) {
            Array.prototype.forEach.call(features, function (element) {
                element.activation = Math.random();
            })
            inference();
            let e = 0.0;
            for (let j = 0; j < outputs.length; j++) {
                e += (outputs[j].error) ** 2;
            }
            current_epoch += (e / outputs.length) ** 2;
        }
        accuracy_record = [current_epoch / 100];
        inference();
        update_text();
    }

    function inference() {
        //for all hidden layers, update activation based on activation_function(x, b) where x is the weighted sum and b is the bias
        for (let i = 0; i < hidden.length; i++) {
            Array.prototype.forEach.call(hidden[i], function (e) {
                e.activation = 0.0;
                if (i == 0) {
                    //calculate dot product
                    for (let j = 0; j < features.length; j++) {
                        e.activation += features[j].activation * e.weights[j];
                    }
                    e.activation /= hidden[i].length
                } else {
                    for (let j = 0; j < hidden[i].length; j++) {
                        e.activation += hidden[i - 1][j].activation * e.weights[j]
                    }
                    e.activation /= hidden[i].length;
                }
                e.activation = activation_function.activation(e);
            })
        }
        //for all outputs update the activation using the activations of the hidden layer
        Array.prototype.forEach.call(outputs, function(element) {
            element.activation = 0.0;
            for (let i = 0; i < hidden[hidden.length - 1].length; i++) {
                element.activation += hidden[hidden.length - 1][i].activation * element.weights[i];
            }
            element.activation /= outputs.length;
            element.activation = activation_function.activation(element);
        })
        compute_loss();
    }

    function compute_loss() {

        for (let i = 0; i < functions.length; i++) {
            outputs[i].error = outputs[i].activation - compute_value(functions[i]); //error of output value is simply (y_pred-y)
        }
        //calculate error for hidden layers
        for (let i = hidden.length - 1; i >= 0; i--) {
            for (let j = 0; j < hidden[i].length; j++) {
                //if last layer then error is proportional to error of outputs
                if (i == hidden.length - 1) {
                    hidden[i][j].error = 0.0;
                    for (let k = 0; k < outputs.length; k++) {
                        hidden[i][j].error += outputs[k].error * outputs[k].weights[j];
                    }
                } else {
                    hidden[i][j].error = 0.0;
                    for (let k = 0; k < hidden[i + 1].length; k++) {
                        hidden[i][j].error += hidden[i + 1][k].error * hidden[i + 1][k].weights[j];
                    }
                }
            }
        }
    }
    //todo add boolean support
    //computes the value based on the string provided by the user that defines the nn behavior
    function compute_value(f) {
        let function_value = "";
        for (let i = 0; i < f.length; i++) {
            switch (f.charAt(i)) {
                case '{':
                    let substring_start = i + 1;
                    while (f.charAt(i) != '}') {
                        i++;
                    }
                    function_value = function_value + String(features[Number(f.substring(substring_start, i))].activation);
                    break;
                default:
                    function_value = function_value + f.charAt(i);
            }
        }
        if (function_value.length == 0) { //if empty string then assume goal was 0
            return 0;
        }
        return (eval(function_value));
    }
    
    function adjust_network_values(batched){
        if (batched){

            for (let i = 0; i < hidden.length; i++) {
                for (let j = 0; j < hidden[i].length; j++) {
                    for (let k = 0; k < hidden[i][j].batch_weight_error.length; k++) {
                        hidden[i][j].weights[k] -= lr * hidden[i][j].batch_weight_error[k] / batch_size;
                    }
                    hidden[i][j].bias -= lr * hidden[i][j].batch_bias_error / batch_size;
                }
            }
            for (let i = 0; i < outputs.length; i++) {
                for (let k = 0; k < outputs[i].weights.length; k++) {
                    outputs[i].weights[k] -= lr * outputs[i].batch_weight_error[k] / batch_size;
                }
                outputs[i].bias -= lr * outputs[i].batch_bias_error / batch_size;
            }

        } else {
            for (let i = 0; i < hidden.length; i++) {
                for (let j = 0; j < hidden[i].length; j++) {
                    if (i == 0) {
                        for (let k = 0; k < hidden[i][j].weights.length; k++) {
                            hidden[i][j].weights[k] -= lr * (hidden[i][j].error) * features[k].activation * hidden[i][j].weights[k] *  activation_function.derivative_wrt_w(hidden[i][j]);
                        }
                    } else {
                        for (let k = 0; k < hidden[i][j].weights.length; k++) {
                            hidden[i][j].weights[k] -= lr * (hidden[i][j].error) * hidden[i - 1][j].activation * hidden[i][j].weights[k] * activation_function.derivative_wrt_w(hidden[i][j]);
                        }
                    }
                    hidden[i][j].bias -= lr * hidden[i][j].error * activation_function.derivative_wrt_b(hidden[i][j]);
                }
            }
            for (let i = 0; i < outputs.length; i++) {
                for (let k = 0; k < outputs[i].weights.length; k++) {
                    outputs[i].weights[k] -= lr * (outputs[i].error) * (hidden[hidden.length - 1][k].activation) * outputs[i].weights[k] * activation_function.derivative_wrt_w(outputs[i]);
                }
                outputs[i].bias -= lr * outputs[i].error * activation_function.derivative_wrt_b(outputs[i]);
            }
        }
    }


</script>

</html>